## 3.1.1 Программа «Bib-eLib» для сбора и обработки библиографических данных на русском языке из электронной библиотеки eLibrary

### Введение

В рамках реализации научного проекта лаборатории научным коллективом МЛ прикладного сетевого анализа разработан служебный результат интеллектуальной деятельности – программа для ЭВМ «Программа «Bib-eLib» для сбора и обработки библиографических данных на русском языке из электронной библиотеки eLibrary».  Программа «Bib-eLib» разработана Д. В. Мальцевой, В. А. Ващенко, Л. В. Капустиной, А. В. Ким, Т. Е. Щегловой, Л.Г. Ципесом в НИУ Высшая школа экономики, являющейся ее правообладателем (свидетельство о государственной регистрации программы для ЭВМ № 2023684182, регистрация в реестре программ для ЭВМ 14.11.2023) (Рис.1).

**Рис. 1. Свидетельство о регистрации программы «Bib-eLib» для сбора и обработки библиографических данных на русском языке из электронной библиотеки eLibrary**
![Рис. 1. Свидетельство о регистрации программы «Bib-eLib» для сбора и обработки библиографических данных на русском языке из электронной библиотеки eLibrary](311_Maltseva_Bib-eLib.png)

Цель работы программы «Bib-eLib» -- сбор и обработка библиографических данных на русском языке из электронной библиотеки eLibrary для применения в области наукометрических и библиометрических исследований, в особенности в области сетевого анализа библиографических сетей.

### Описание работы программы

Программа «Bib-eLib» характеризуется следующими функциональными характеристиками:

* Программа осуществляет выгрузку массива данных о научных публикациях через API электронной библиотеки eLibrary при наличии предварительно заключенного контракта с Национальной электронной библиотекой НЭБ;
* Программа проводит предварительную обработку массива данных о научных публикациях, выгруженных через API электронной библиотеки eLibrary, в части имен авторов и их аффилиаций (организаций);
* Программа реализовывает алгоритм дизамбигуации авторов публикаций в предварительно обработанном массиве данных путем создания новых универсальных идентификаторов авторов;
* Программа проводит анализ итогового массива данных по основным статистическим метрикам в области библиометрических исследований и визуализировать распределение подсчитанных метрик;
* Программа создает двумодальную сеть связей между научными публикациями и их авторами в формате с расширением .net, пригодном для дальнейшей обработки в программе для анализа и визуализации больших сетей Pajek.

Программа подходит для реализации на Windows, MacOS, Linux на базе интегрированных с ОС графических пользовательских интерфейсов (GUI). Программа написана на языке программирования Python и включает архив файлов формата Jupyter Notebook (.ipynb) размером 266 КБ. Описание файлов .ipynb-files приводится ниже. В качестве примера для сбора взят массив данных о публикациях российских социологов, который был собран в рамках проекта "Паттерны коллаборации в Российском социологическом сообществе" (грант РНФ, руководитель Д.В. Мальцева, 2021-2023 гг.).

1.  Файл "0. Выгрузка данных о статьях авторов.ipynb" - в этом файле производится выгрузка данных о статьях конкретных авторов на eLibrary через сервис API Elibrary 011 (не используется напрямую в программе, но может быть полезным).
   В качестве примера, в этом файле Jupyter Notebook производится выгрузка данных eLibrary по публикациям российских авторов в области социологии. Осуществляется импорт необходимых библиотек, загружаются id авторов, данные о которых необходимо выгрузить, производится выгрузка кратких данных обо всех статьях этих авторов из API Elibrary.
   Основной код выгрузки к API-011 Elibrary был подготовлен Ликой Капустиной в сентябре-октябре 2022 года. Цель выгрузки - выгрузить краткие справочные данные о статьях всех уникальных авторов, встречающихся в основном массиве данных (но не все данные по статьям).
   Собранные данные не использовались для дообновления финальных данных проекта, но код в этом ноутбуке может быть полезен для других исследователей.
   Результат выгрузки – файл all_final_authors_with_papers.csv, содержащий в себе информацию о всех статьях всех авторов, присутствовавших в 8 колонках наших изначальных данных.

2.  Файл "1. Выгрузка данных по статьям.ipynb" – представленный в этом файле код используется для выгрузки данных о статьях через API Elibrary.
   В этом файле Jupyter Notebook производится парсинг (выгрузка данных) данных eLibrary по статьям через API eLibrary для проекта "Паттерны коллаборации в Российском социологическом сообществе". Осуществляется импорт необходимых библиотек, загружаются id необходимых к выгрузке статьи, производится сама выгрузка основного массива данных.
   Основной код выгрузки был подготовлен Львом Ципесом, в доработке кода и выгрузке данных участвовали Василиса Ващенко и Лика Капустина. Выгрузка производилась в июне-июле 2022 года. Эта версия была закончена и прокомментирована Ликой Капустиной.
   Представленный код можно использовать для выгрузки данных о статьях через API Elibrary. Предварительно вам нужно заключить договор с Elibrary, и тогда вы получите доступ к одному из сервисов API по IP-адресу, указанному в договоре.
   Для работы нужен файл формата .txt с id статей, информацию о которых нужно выгрузить через API Elibrary.
   Процесс выгрузки данных о статьях через API Elibrary происходит в несколько шагов:
   - Шаг 1: подготовка к работе;
   - Шаг 2: выгрузка данных
   - Шаг 3: сохранение данных
   В результате получаются следующие файлы:
   - Промежуточные файлы с данными в формате .csv и .xlsx, которые сохраняются локально в рабочую директорию каждую 1000 итераций (с названием в формате df_текущая дата_число строк_rows.формат файла);
   - final_data.csv - pandas.DataFrame с информацией о всех статьях, находящихся в изначальном списке, в формате .csv;
   - final_data.xlsx - pandas.DataFrame с информацией о всех статьях, находящихся в изначальном списке, в формате .xlsx;
  
3. Файл "2.1. Предобработка данных и получение идентифицирующих признаков.ipynb" – в этом файле проводится предобработка данных, выгруженных на этапе 1, с точки зрения работы с именами авторов и получения идентифицирующих признаков.
   Часть 1. Предобработка данных
   На данном этапе стоит задача предобработать данные, выгруженные через API Elibrary ранее (см. файл «1. Выгрузка данных по статьям»). На этом этапе стоит несколько задач:
   * Предобработать данные по русскоязычным фамилиям и инициалам;
   * Предобработать данные по англоязычным фамилиям и инициалам;
   * Предобработать данные по русско- и англоязычным аффилиациям;
   * Провести процедуру присвоения собственных id авторов;
   В части 1 проводятся две первые процедуры - предобработка данных по русско- и англоязычным фамилиям и инициалам. Такая необходимость возникает  в связи с тем, что в данных достаточно много авторов без id во внутренней системе eLibrary. Этот факт осложняет дальнейшую работу с данными и их анализ – нельзя построить сети на основании id авторов, если они не достаточно корректные. Поэтому было принято решение подготовить собственные id авторов, основываясь на ФИО и данных об аффилиациях авторов. Однако на этом этапе возникла проблема – eLibrary не контролирует единообразность записи фамилий, имен и инициалов; туда можно вписать разные знаки препинания; иногда в фамилии вписываются сразу и фамилиии, и инициалы, и так далее.
   В этом ноутбуке демонстрируются разные проблемы и способы их решения. Получаемые в результате первой части предобработки файлы:
   * problem1.xlsx - строчки с информацией о статьях, для которых отсутствует информация даже о первом авторе (то есть, нет информации об авторах вообще). Необходимо заполнение вручную.
   * problem2.xlsx - строчки с информацией о статьях, в фамилиях и инициалах авторов которых встречаются вопросительные знаки. Необходимо заполнение вручную.
   * problem3.xlsx - строчки с информацией о статьях, среди авторов которых встречаются авторы с не-русскими фамилиями если в разделе с инициалами у них не указаны иниициалы (то есть, в ячейку с фамилией отнесена и фамилия, и инициалы). Необходимо заполнение вручную.

4. Файл «2.2. Обработка аффилиаций.ipynb» – в этом файле проводится предобработка данных, выгруженных на этапе 1, с точки зрения работы с аффилиациями авторов.
   В этом файле проводится работа по дедупликации аффилиаций авторов путем их чистки и присуждения id.
   Вначале составляется общий список всех аффилиаций, затем рассматриваются варианты их сокращения до аффилаций и создается словарь сокращений. Работа подразумевает следующие шаги:
   * Шаг 0: Предварительная очистка данных
   * Шаг 1: Работа с ID аффилиаций
   * Шаг 2: Работа с английским переводом аффилиаций
   * Шаг 3: Создаем новые id для неидентифицированных аффилиаций
   * Шаг 4: Создание новых ID для авторов
   * Шаг 5: Дедупликация авторов по новым ID

5. Файл «2.3. Пост-обработка_новых_ID.ipynb» – в этом файле проводится пост-бработка данных – создание новых универсальных ID авторов на основе почищенных имен авторов и аффилиаций. Работа по дедупликации авторов осуществляется на основании ID авторов и аффилиаций, присужденных на предыдущих этапах 2.1 и 2.2.
   Для новых ID авторов были рассчитаны попарные расстояния Дамерау-Левенштайна (см. п. 5 в файле 2.2), и в этом файле новые ID анализируются на предмет пересечения важных идентифицирующих признаков для финализации дедупликации. Работа включает следующие шаги:
   * Шаг 1: Обработка авторов с наличествующим идентификатором
   * Шаг 2: Обработка авторов с отсутствующим идентификаторов
   * Шаг 3: Сбор результатов обработки воедино
   * Шаг 4: Изменение рабочего файла с данными

6. Файл «"3. Анализ данных и визуализация.ipynb"» – в этом файле анализируются предварительно собранные и обработанные файлы, а также создаются графики. Работа подразумевает следующие шаги:
   * Пункт 1. Распределение статей по числу авторов
   * Пункт 2. Распределение цитирований
   * Пункт 3. Абстракты и ключевые слова
   * Пункт 4. Статистики по авторам

7. Файл «"4. Создание сетевых файлов для Pajek.ipynb"» – в этом файле создаются сетевые файлы для работы с графами в формате Pajek. В настоящее время прописанный код подразумевает создание двумодальной сети формата «Работа – Автор», на основе которой могут строиться сети коллабораций (согласно цели проекта "Паттерны коллаборации в Российском социологическом сообществе"), однако в дальнейшем планируется написание кода для других видов сетей («Работа – Журнал», «Работа – Ключевое слово», сети соприсутствия слов в аннотациях / названиях статей и др.).

Согласно разработанной в лаборатории методологии анализа библиографических сетевых данных на русском языке дальнейший анализ сетевых данных осуществляется в программе для анализа и визуализации больших сетей Pajek.

Файлы формата Jupyter Notebook расположены в репозитории на GitHub по ссылке: [https://github.com/Daria-Maltseva/Collaboration](https://github.com/Daria-Maltseva/Collaboration). Коллективом лаборатории планируется работа по продолжению развития программ ЭВМ для анализа русскоязычных данных и разработка полноценного отчуждаемого пакета для библиометрического анализа русскоязычных публикаций на языке программирования Python.